{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "review_model.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kovus380/testtest/blob/master/review_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dNaX5bRG1CF"
      },
      "source": [
        "!apt-get update\n",
        "!apt-get install g++ openjdk-8-jdk \n",
        "!pip install konlpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CF4sG2dUVhT"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import urllib.request\n",
        "from konlpy.tag import Okt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1kpcP1CVb9y"
      },
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/bab2min/corpus/master/sentiment/naver_shopping.txt\", filename=\"ratings_total.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ebAtlBGVd7l"
      },
      "source": [
        "total_data = pd.read_table('ratings_total.txt', names=['ratings', 'reviews'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bV8NRe8qVjAF"
      },
      "source": [
        "total_data['label'] = np.select([total_data.ratings > 3], [1], default=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPRHypwNVmDy"
      },
      "source": [
        "total_data['ratings'].nunique(), total_data['reviews'].nunique(), total_data['label'].nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY_zFWBkVp_A"
      },
      "source": [
        "total_data.drop_duplicates(subset=['reviews'], inplace=True)\n",
        "print(total_data.isnull().values.any())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOo193ZQVszD"
      },
      "source": [
        "train_data, test_data = train_test_split(total_data, test_size = 0.25, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu8NnDsvVxY1"
      },
      "source": [
        "train_data['reviews'] = train_data['reviews'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
        "train_data['reviews'].replace('', np.nan, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR8obfz1Vy70"
      },
      "source": [
        "test_data.drop_duplicates(subset = ['reviews'], inplace=True) # 중복 제거\n",
        "test_data['reviews'] = test_data['reviews'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") # 정규 표현식 수행\n",
        "test_data['reviews'].replace('', np.nan, inplace=True) # 공백은 Null 값으로 변경\n",
        "test_data = test_data.dropna(how='any') # Null 값 제거"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlKRzVjoV13-"
      },
      "source": [
        "okt = Okt()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6ebEqAwV5gO"
      },
      "source": [
        "stopwords = ['도', '는', '다', '의', '가', '이', '은', '한', '에', '하', '고', '을', '를', '인', '듯', '과', '와', '네', '들', '듯', '지', '임', '게']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzHUs4-iIEqV"
      },
      "source": [
        "train_data['tokenized'] = train_data['reviews'].apply(okt.morphs)\n",
        "train_data['tokenized'] = train_data['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPmIiCzqV8sd"
      },
      "source": [
        "test_data['tokenized'] = test_data['reviews'].apply(okt.morphs)\n",
        "test_data['tokenized'] = test_data['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SolqjVnqWCVR"
      },
      "source": [
        "negative_words = np.hstack(train_data[train_data.label == 0]['tokenized'].values) # 부정 단어\n",
        "positive_words = np.hstack(train_data[train_data.label == 1]['tokenized'].values) # 긍정 단어"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q5Cmgy2WEyg"
      },
      "source": [
        "from collections import Counter\n",
        "negative_word_count = Counter(negative_words)\n",
        "positive_word_count = Counter(positive_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87LNSiKXWLPa"
      },
      "source": [
        "X_train = train_data['tokenized'].values\n",
        "y_train = train_data['label'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jenmrCmY1dch"
      },
      "source": [
        "import csv \n",
        "path = '/content/X_train.csv'\n",
        "with open(path, 'w') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerows(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WUHFe0e130H"
      },
      "source": [
        "X_train = []\n",
        "vocab_size = 42019\n",
        "with open(path, 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    for idx, content in enumerate(reader):\n",
        "        X_train.append(content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56xi6uJgWOZB"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_lTaEUcWR1p"
      },
      "source": [
        "vocab_size = 42019"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ls4QF0BBWVW3"
      },
      "source": [
        "tokenizer = Tokenizer(vocab_size, oov_token = 'OOV')\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NhTn47PMu3r"
      },
      "source": [
        "y_train = np.array(train_data['label'])\n",
        "y_test = np.array(test_data['label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-OHj2fBWdmr"
      },
      "source": [
        "max_len = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1f2Qf1-We9K"
      },
      "source": [
        "X_train = pad_sequences(X_train, maxlen = max_len)\n",
        "X_test = pad_sequences(X_test, maxlen = max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbDGBVxUWgr2"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZP22GeCjWibG"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 100))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnSbLaRXWjp6"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "mc = ModelCheckpoint('review_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPr0_5_FWlFf"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=60, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1HuhsuUWmVO"
      },
      "source": [
        "loaded_model = load_model('review_model.h5')\n",
        "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}